{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naver News Search Open API**\n",
    "### **목표**\n",
    "1. **네이버 뉴스 검색 API 호출**:  \n",
    "   - 키워드를 기반으로 뉴스 데이터를 검색합니다.\n",
    "2. **데이터 분석 및 활용**:  \n",
    "   - 검색된 데이터를 정리 및 가공하여 원하는 정보를 추출합니다.\n",
    "3. **뉴스 데이터 웹크롤링**:  \n",
    "   - API로 제공되지 않는 추가 데이터를 수집하기 위해 웹 크롤링을 수행합니다.\n",
    "\n",
    "### **작성자 정보**\n",
    "Written by [**Yujin_nKim**](https://github.com/Yujin-nKim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 API 인증 키 설정 \n",
    "# 네이버 개발자 센터에서 발급받은 클라이언트 ID와 시크릿 키를 이용합니다. \n",
    "my_client_id = \"FHNP6NJ_GuKgxhnCOjUi\" # 네이버 클라이언트 ID\n",
    "my_client_secret = \"kgX6c9lqKR\" # 네이버 클라이언트 시크릿 키 \n",
    "\n",
    "# 네이버 뉴스 검색 APi의 엔드포인트 URL (json 형식)\n",
    "base_url = \"https://openapi.naver.com/v1/search/news.json\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 파라미터 설정\n",
    "searchWord = \"재테크\" # 검색어\n",
    "display = 100 # 한 번에 표시할 검색 결과 개수 (기본값: 10, 최댓값: 100)\n",
    "start = 1 # 검색 시작 위치 (기본값: 1, 최댓값: 1000)\n",
    "sort = \"sim\" # 검색 결과 정렬 방식 (sim - 정확도순 (기본값, 내림차순) / date - 날짜순 (내림차순)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 호출 결과로 받은 뉴스 데이터 리스트를 출력하는 함수 \n",
    "# items (list) : 뉴스 검색 결과의 아이템 목록\n",
    "def print_item(items):\n",
    "    for item in items:\n",
    "        print(\"제목:\", item[\"title\"].replace(\"<b>\", \"\").replace(\"</b>\", \"\"))\n",
    "        print(\"요약:\", item[\"description\"].replace(\"<b>\", \"\").replace(\"</b>\", \"\"))\n",
    "        print(\"링크:\", item[\"originallink\"])\n",
    "        print(\"작성일:\", item[\"pubDate\"])\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 뉴스 검색 결과를 CSV 파일로 저장하는 함수\n",
    "# items (list) : 뉴스 검색 결과의 아이템 목록\n",
    "# filename (str) : 저장할 CSV 파일 이름 (기본값: 'news_results.csv')\n",
    "def save_to_csv(items, filename=\"news_results.csv\"):\n",
    "    # CSV 파일 열기\n",
    "    with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # 헤더 작성\n",
    "        writer.writerow([\"제목\", \"요약\", \"원문 링크\", \"네이버 뉴스 링크\", \"작성일\"])\n",
    "        \n",
    "        # 데이터 작성\n",
    "        for item in items:\n",
    "            title = item[\"title\"].replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
    "            description = item[\"description\"].replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
    "            originallink = item[\"originallink\"]\n",
    "            link = item[\"link\"]\n",
    "            pubDate = item[\"pubDate\"]\n",
    "            \n",
    "            writer.writerow([title, description, originallink, link, pubDate])\n",
    "\n",
    "    print(f\"결과가 {filename}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요청 URL: https://openapi.naver.com/v1/search/news.json?query=%EC%9E%AC%ED%85%8C%ED%81%AC&display=100&start=1&sort=sim\n",
      "1번째 결과부터 100까지 데이터를 가져왔습니다.\n",
      "요청 URL: https://openapi.naver.com/v1/search/news.json?query=%EC%9E%AC%ED%85%8C%ED%81%AC&display=100&start=101&sort=sim\n",
      "101번째 결과부터 200까지 데이터를 가져왔습니다.\n",
      "결과가 news_results.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 네이버 검색 API 예제 - 뉴스 검색\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "# 네이버 API 인증 정보\n",
    "client_id = my_client_id \n",
    "client_secret = my_client_secret\n",
    "\n",
    "all_items = [] # 모든 뉴스 데이터를 저장할 리스트\n",
    "\n",
    "while True:\n",
    "    # 검색 파라미터 설정\n",
    "    query_params = {\n",
    "        \"query\": urllib.parse.quote(searchWord),\n",
    "        \"display\": display, \n",
    "        \"start\": start,\n",
    "        \"sort\": sort\n",
    "    }\n",
    "\n",
    "    query_string = \"&\".join([f\"{key}={value}\" for key, value in query_params.items()])\n",
    "    url = f\"{base_url}?{query_string}\"\n",
    "\n",
    "    # API 요청 URL 출력\n",
    "    print(\"요청 URL:\", url)\n",
    "\n",
    "    # 요청 객체 생성\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "\n",
    "    # API 요청 및 응답 처리 \n",
    "    try:\n",
    "        response = urllib.request.urlopen(request)\n",
    "        rescode = response.getcode()\n",
    "        if(rescode==200): # 성공 응답 \n",
    "            response_body = response.read().decode('utf-8')\n",
    "            data = json.loads(response_body)\n",
    "            \n",
    "            # 전체 결과 수와 현재 페이지의 아이템 가져오기\n",
    "            #total_results = data[\"total\"]\n",
    "            total_results = 200 # test\n",
    "            items = data[\"items\"]\n",
    "            all_items.extend(items)\n",
    "            \n",
    "            print(f\"{start}번째 결과부터 {start + len(items) - 1}까지 데이터를 가져왔습니다.\")\n",
    "            \n",
    "            # 다음 페이지로 이동\n",
    "            start += display\n",
    "            \n",
    "            # 더 이상 가져올 데이터가 없으면 중단\n",
    "            if start > total_results or not items:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error Code: {response.getcode()}\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", e)\n",
    "        \n",
    "# 모든 데이터 CSV로 저장\n",
    "save_to_csv(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 내용 : \n",
      "[<article class=\"go_trans _article_content\" id=\"dic_area\">\n",
      "<strong class=\"media_end_summary\">엔비디아에 HBM 공급 시 실적 개선 기대</strong><span class=\"end_photo_org\"><div class=\"nbd_im_w _LAZY_LOADING_WRAP\">\n",
      "<div class=\"nbd_a _LAZY_LOADING_ERROR_HIDE\" id=\"img_a1\">\n",
      "<img alt=\"서울 서초구 삼성전자 사옥. 2024.10.31 연합뉴스\" class=\"_LAZY_LOADING _LAZY_LOADING_INIT_HIDE\" data-src=\"https://imgnews.pstatic.net/image/081/2025/01/14/0003510900_001_20250114164822336.jpg?type=w860\" id=\"img1\" style=\"display: none;\">\n",
      "</img></div>\n",
      "</div><em class=\"img_desc\">서울 서초구 삼성전자 사옥. 2024.10.31 연합뉴스</em></span><br/><br/>지난해 삼성전자의 주가가 폭락하며 시가총액이 156조원 증발한 가운데, 올해 부활에 성공할지가 엔비디아에 달려있다는 전망이 나오고 있습니다. 삼성전자가 엔비디아 요구 사항을 충족시켜 고대역폭메모리(HBM) 공급에 성공할 경우 실적이 개선되겠지만, 이 과정이 순탄치만은 않을 것으로 예상되는 만큼 삼성전자의 기술력과 대응 능력이 시험대에 올랐다는 평가입니다.<br/><br/>13일(현지시간) CNBC 보도에 따르면, 삼성전자는 현재 엔비디아가 자사 고대역폭메모리(HBM) 사용을 승인하길 기다리고 있으며, 이는 회사 수익성 개선의 핵심 요소라는 분석이 나오고 있습니다.<br/><br/><!-- MobileAdNew center -->지난해 삼성전자 주가는 8만 7000원대까지 치솟았다가 연말까지 40%가량 떨어져 5만 3000원대로 주저앉았는데요.<br/><br/>CNBC는 “삼성전자의 주가 폭락은 지금까지 인공지능(AI) 붐을 놓쳤다는 시장의 인식이라는 한 가지 주요 요인 때문이었다”며 “AI 붐은 다른 기술기업의 주가를 크게 끌어올린반면 삼성은 이 흐름에서 뒤처진 모습을 보였다”고 분석했습니다.<br/><br/>최근 삼성전자가 시장 예측을 크게 밑도는 4분기 잠정 실적을 발표했음에도 불구하고 주가가 상승했던 배경 역시 AI 관련 시장의 기대감 때문입니다.<br/><br/>젠슨 황 엔비디아 최고경영자(CEO)는 지난주 삼성전자가 엔비디아의 요구사항을 충족시키려면 HBM을 재설계해야 하지만 수행 능력은 충분하다고 언급했습니다. 그는 “삼성이 HBM 메모리로 성공할 것이라고 확신한다”고 말하기도 했습니다.<br/><br/><!-- MobileAdNew center -->삼성전자에 엔비디아가 중요한 이유는 명확합니다. 엔비디아의 칩과 시스템은 대규모 AI 모델 훈련에 사용되는 데이터센터에 공급되는데 이 시스템 일부에 HBM이 필요한 상황이죠.<br/><br/>그간 삼성은 기존 메모리 분야에서의 선도적 위치를 바탕으로 엔비디아의 주요 공급업체가 될 것으로 기대를 모았지만 현재까지 그런 일은 일어나지 않았습니다. 오히려 삼성이 HBM 분야에서 경쟁사인 SK하이닉스에 뒤처졌다는 분석도 나오는데요. 시장에서는 삼성의 HBM 기술에 대한 투자 부족을 원인으로 지적하고 있습니다.<br/><br/>삼성은 현재 엔비디아의 요구사항을 충족시키기 위해 HBM을 재설계하고 있는 것으로 알려졌는데요. 시장조사기관 카운터포인트리서치는 “삼성전자가 칩 크기나 비용에서 전력 소비와 열을 제어하는 방향으로 초점을 옮기고 있다”며 “이를 바꾸는 데 수년이 걸리겠지만 전환점은 2025년이 될 것으로 예상된다”고 했습니다.<br/><br/>한편 삼성전자는 올해 실적 개선을 위해 HBM 사업에 총력을 기울이고 있습니다. 내년 하반기 양산을 목표로 6세대 HBM인 ‘HBM4’를 개발 중입니다.\n",
      "\t\t</article>]\n",
      "\n",
      "신문사 이름 : 서울신문\n",
      "기자 이름 : 김성은 기자\n",
      "기자의 구독자 수 : <em class=\"media_journalistcard_summary_subscribe_value _SUBSCRIBE_COUNT_TEXT\">0</em>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}\n",
    "data = requests.get('https://n.news.naver.com/mnews/article/081/0003510900?sid=101',headers=headers)\n",
    " \n",
    "soup = BeautifulSoup(data.text, 'html.parser')\n",
    "\n",
    "content = soup.select('#dic_area')\n",
    "newspaper_name = soup.select_one('.media_end_head_top_logo_img').get(\"alt\")\n",
    "reporter_name = soup.select_one('.media_journalistcard_summary_name_text').text\n",
    "subscribe_tag = soup.select('.media_journalistcard_summary_subscribe_value._SUBSCRIBE_COUNT_TEXT')\n",
    "\n",
    "print(f\"뉴스 내용 : \\n{content}\\n\")\n",
    "print(f\"신문사 이름 : {newspaper_name}\")\n",
    "print(f\"기자 이름 : {reporter_name}\")\n",
    "print(f\"기자의 구독자 수 : {subscribe_tag[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
